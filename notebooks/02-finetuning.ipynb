{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dotenv\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments\n",
    ")\n",
    "from src.training_utils import GenderLossTrainer\n",
    "from src.utils import read_config\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from src.data_utils import prepare_dataset_gender, prepare_dataset_gender_stories\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "login(token=os.getenv('huggingface_token'))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=os.getenv('WANDB_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_configs = read_config('../configs/llm_config.yaml')\n",
    "print(llm_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(llm_configs['local_generative_model_name'])\n",
    "model = AutoModelForCausalLM.from_pretrained(llm_configs['local_generative_model_name'])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom gender dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gender = prepare_dataset_gender('../configs/dataset_config.yaml', '../data/short_profession_templates.txt', print_dataset_info=True, reduced_number_of_train_templates=35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gender['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_ds_extra_id = -777\n",
    "\n",
    "def format_example(example):\n",
    "    # Basic instruction prompt format\n",
    "    instruction = example[\"context\"]\n",
    "    label = [tokenizer.convert_tokens_to_ids(pr) for pr in example[\"pronoun_list\"]]\n",
    "    input_ids = tokenizer(instruction, truncation=True, max_length=256).input_ids\n",
    "    length = len(input_ids)\n",
    "    label.append(length)\n",
    "    label.append(gender_ds_extra_id)\n",
    "   \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": label\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gender_train = dataset_gender['train'].map(format_example, remove_columns=dataset_gender['train'].column_names)\n",
    "dataset_gender_validation = dataset_gender['validation'].map(format_example, remove_columns=dataset_gender['validation'].column_names)\n",
    "dataset_gender_test = dataset_gender['test'].map(format_example, remove_columns=dataset_gender['test'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gender_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom stories dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stories = prepare_dataset_gender_stories('../data/stories', reduced_number_of_stories_per_profession=17)\n",
    "dataset_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stories['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example_stories(example, max_length=256):\n",
    "    instruction = example[\"instruction\"]\n",
    "    response = example[\"response\"]\n",
    "    prompt = f\"{instruction}\\n\"\n",
    "    prompt_ids = tokenizer(prompt, truncation=True, max_length=max_length).input_ids\n",
    "    response_ids = tokenizer(response, truncation=True, max_length=max_length).input_ids\n",
    "    input_ids = prompt_ids + response_ids\n",
    "    labels = [-100] * len(prompt_ids) + response_ids\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stories_train = dataset_stories['train'].map(format_example_stories, remove_columns=dataset_stories['train'].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dolly dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dolly_dataset(max_length=512, print_dataset_info=False, number_of_train_samples=None):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the Dolly dataset to match the custom dataset format.\n",
    "    \n",
    "    Args:\n",
    "        tokenizer: The tokenizer to encode the texts.\n",
    "        max_length: Maximum sequence length.\n",
    "    \n",
    "    Returns:\n",
    "        DatasetDict\n",
    "    \"\"\"\n",
    "    dolly = load_dataset(\"databricks/databricks-dolly-15k\")\n",
    "    dolly = dolly[\"train\"]\n",
    "    if number_of_train_samples:\n",
    "        dolly = dolly.select(range(number_of_train_samples))\n",
    "    if print_dataset_info:\n",
    "        print(dolly)\n",
    "        print(dolly[0])\n",
    "    \n",
    "    def preprocess_dolly(example):\n",
    "        instruction = example[\"instruction\"]\n",
    "        context = example.get(\"context\", \"\")\n",
    "        response = example[\"response\"]\n",
    "\n",
    "        if context:\n",
    "            prompt = f\"Instruction:\\n{instruction}\\n\\nContext:\\n{context}\\n\\nAnswer:\"\n",
    "        else:\n",
    "            prompt = f\"Instruction:\\n{instruction}\\n\\nAnswer:\"\n",
    "\n",
    "        prompt_ids = tokenizer(prompt, truncation=True, max_length=max_length).input_ids\n",
    "        response_ids = tokenizer(response, truncation=True, max_length=max_length).input_ids\n",
    "        \n",
    "        input_ids = prompt_ids + response_ids\n",
    "        labels = [-100] * len(prompt_ids) + response_ids\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        \n",
    "    dolly = dolly.map(preprocess_dolly, remove_columns=dolly.column_names)\n",
    "    if print_dataset_info:\n",
    "        print(dolly)\n",
    "        print(dolly[0])\n",
    "    \n",
    "    return dolly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolly_dataset = load_dolly_dataset(print_dataset_info=True, number_of_train_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(features):\n",
    "    # Collate input_ids and labels into padded tensors\n",
    "    input_ids = [torch.tensor(f[\"input_ids\"]) for f in features]\n",
    "    labels = [torch.tensor(f[\"labels\"]) for f in features]\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-100)  # -100 for ignored tokens\n",
    "\n",
    "    if input_ids.shape[1] < labels.shape[1]:\n",
    "        input_ids = torch.nn.functional.pad(\n",
    "            input_ids,\n",
    "            (0, labels.shape[1] - input_ids.shape[1]),\n",
    "            value=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    if input_ids.shape[1] > labels.shape[1]:\n",
    "        labels = torch.nn.functional.pad(\n",
    "            labels,\n",
    "            (0, input_ids.shape[1] - labels.shape[1]),\n",
    "            value=-100\n",
    "        )\n",
    "    return {\"input_ids\": input_ids, \"labels\": labels, \"attention_mask\": (input_ids != tokenizer.pad_token_id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_train = concatenate_datasets([dataset_gender_train, dataset_stories_train, dolly_dataset])\n",
    "merged_train = merged_train.shuffle(seed=42)\n",
    "merged_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = read_config('../configs/train_config.yaml')\n",
    "\n",
    "target_modules = []\n",
    "\n",
    "for layer_idx in range(train_config['lora_train_config']['layer_numbers']['start'], train_config['lora_train_config']['layer_numbers']['end']):\n",
    "    for proj in train_config['lora_train_config']['layers_to_train']:\n",
    "        target_modules.append(f\"layers.{layer_idx}.{train_config['lora_train_config']['module_to_train']}.{proj}\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=train_config['lora_train_config']['r'],\n",
    "    lora_alpha=train_config['lora_train_config']['lora_alpha'],\n",
    "    target_modules=target_modules,\n",
    "    lora_dropout=train_config['lora_train_config']['lora_dropout'],\n",
    "    bias=train_config['lora_train_config']['bias'],\n",
    "    task_type=train_config['lora_train_config']['task_type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_params(model):\n",
    "    all_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return all_params, trainable_params\n",
    "\n",
    "\n",
    "# Count parameters in the LoRA-adapted model\n",
    "all_params, trainable_params = count_trainable_params(lora_model)\n",
    "print(f\"All parameters: {all_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "print(f\"Trainable parameters share: {round(trainable_params / all_params * 100, 4)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb.init(project=\"gender-bias-llm\", config=train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../test/gender_only_ckpt\",\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=50,\n",
    "    eval_steps=200,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_dir=\"../test/logs\",\n",
    "    report_to=\"wandb\",\n",
    "    # gradient_accumulation_steps=8\n",
    ")\n",
    "\n",
    "trainer = GenderLossTrainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=merged_train,\n",
    "    eval_dataset=dataset_validation,\n",
    "    data_collator=data_collator,\n",
    "    lambda_gender=train_config['lambda_gender'],\n",
    "    gender_ds_extra_id=gender_ds_extra_id,\n",
    "    p_total_power=train_config['p_total_power']\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
